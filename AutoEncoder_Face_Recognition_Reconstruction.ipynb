{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "94794411-b2d8-495b-9ea2-f6921be16a75",
      "metadata": {
        "id": "94794411-b2d8-495b-9ea2-f6921be16a75"
      },
      "source": [
        "# Yale Face Dataset B"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8aa4cf4f-e826-435c-b71f-c3d1656453eb",
      "metadata": {
        "id": "8aa4cf4f-e826-435c-b71f-c3d1656453eb"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import scipy.io\n",
        "import seaborn as sns\n",
        "\n",
        "plt.rcParams['figure.figsize'] = [10, 10]\n",
        "plt.rcParams.update({'font.size': 18})\n",
        "plt.rcParams['figure.constrained_layout.use'] = True\n",
        "\n",
        "mat_contents = scipy.io.loadmat('allFaces.mat')\n",
        "faces = mat_contents['faces']\n",
        "m = int(mat_contents['m'])\n",
        "n = int(mat_contents['n'])\n",
        "nfaces = np.ndarray.flatten(mat_contents['nfaces'])\n",
        "\n",
        "y = np.zeros((faces.shape[1],))\n",
        "j = 0\n",
        "classes = list(range(len(nfaces)))\n",
        "for i in nfaces:\n",
        "  y[j:j+i] = classes.pop(0)\n",
        "  j = j + i\n",
        "\n",
        "print(\"Total dataset size:\")\n",
        "print(f\"n_samples: {faces.shape[1]}\")\n",
        "print(f\"n_features: {m*n}\")\n",
        "print(f\"n_classes: {len(nfaces)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8adb8932-7ccf-4ac4-9264-908f25ec5be6",
      "metadata": {
        "id": "8adb8932-7ccf-4ac4-9264-908f25ec5be6"
      },
      "outputs": [],
      "source": [
        "allPersons = np.zeros((n*6,m*6))\n",
        "count = 0\n",
        "\n",
        "for j in range(6):\n",
        "    for k in range(6):\n",
        "        allPersons[j*n : (j+1)*n, k*m : (k+1)*m] = np.reshape(faces[:,np.sum(nfaces[:count])],(m,n)).T\n",
        "        count += 1\n",
        "\n",
        "img = plt.imshow(allPersons)\n",
        "img.set_cmap('gray')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b06e7d01-489c-46e0-a86b-c135c0676c02",
      "metadata": {
        "id": "b06e7d01-489c-46e0-a86b-c135c0676c02"
      },
      "outputs": [],
      "source": [
        "for person in range(len(nfaces)):\n",
        "    subset = faces[:,sum(nfaces[:person]) : sum(nfaces[:(person+1)])]\n",
        "    allFaces = np.zeros((n*8,m*8))\n",
        "\n",
        "    count = 0\n",
        "\n",
        "    for j in range(8):\n",
        "        for k in range(8):\n",
        "            if count < nfaces[person]:\n",
        "                allFaces[j*n:(j+1)*n,k*m:(k+1)*m] = np.reshape(subset[:,count],(m,n)).T\n",
        "                count += 1\n",
        "\n",
        "    img = plt.imshow(allFaces)\n",
        "    img.set_cmap('gray')\n",
        "    plt.axis('off')\n",
        "\n",
        "    fileName = f\"P{person+1:02d}\"\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "854c0a01-8489-4039-9e87-76e56bdadeef",
      "metadata": {
        "id": "854c0a01-8489-4039-9e87-76e56bdadeef"
      },
      "outputs": [],
      "source": [
        "sns.set(style=\"darkgrid\")\n",
        "plt.rc('xtick', labelsize=22)\n",
        "plt.rc('ytick', labelsize=22)\n",
        "plt.rc('axes', labelsize=22)\n",
        "\n",
        "fig = plt.figure(figsize=(18, 10))\n",
        "ax = sns.countplot(x=y, hue=y, palette='icefire', legend=False)\n",
        "\n",
        "ax.set_xticks(range(len(set(y))))\n",
        "ax.set_xticklabels(range(1, 39))\n",
        "\n",
        "ax.set_ylabel(\"Count\")\n",
        "ax.set_xlabel(\"Person\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "683cb69a-5100-47f4-9d94-232c7ec5682a",
      "metadata": {
        "id": "683cb69a-5100-47f4-9d94-232c7ec5682a"
      },
      "source": [
        "# Eigenfaces with PCA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4effcf1f-9358-42c2-b6c5-69253adfeb41",
      "metadata": {
        "id": "4effcf1f-9358-42c2-b6c5-69253adfeb41"
      },
      "outputs": [],
      "source": [
        "from time import time\n",
        "import os\n",
        "\n",
        "plt.rcParams['figure.figsize'] = [8, 8]\n",
        "plt.rcParams.update({'font.size': 18})\n",
        "plt.rcParams['figure.constrained_layout.use'] = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c84998d0-4f79-4ff9-9b72-2c91dbd07492",
      "metadata": {
        "id": "c84998d0-4f79-4ff9-9b72-2c91dbd07492"
      },
      "outputs": [],
      "source": [
        "trainingFaces = faces[:,:np.sum(nfaces[:36])]\n",
        "avgFace = np.mean(trainingFaces,axis=1)\n",
        "\n",
        "# Compute eigenfaces on mean-subtracted training data\n",
        "print(\"Computing eigenfaces / Performing SVD on face library\")\n",
        "X = trainingFaces - np.tile(avgFace,(trainingFaces.shape[1],1)).T\n",
        "t0 = time()\n",
        "U, S, VT = np.linalg.svd(X,full_matrices=0)\n",
        "print(f\"done in {time()-t0:0.3f}s\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e4df8b2f-e194-4c2c-b2e4-da80bb6180e5",
      "metadata": {
        "id": "e4df8b2f-e194-4c2c-b2e4-da80bb6180e5"
      },
      "outputs": [],
      "source": [
        "# Plot avg face\n",
        "fig1 = plt.figure()\n",
        "ax = fig1.add_subplot()\n",
        "img_avg = ax.imshow(np.reshape(avgFace,(m,n)).T)\n",
        "img_avg.set_cmap('gray')\n",
        "plt.axis('off')\n",
        "plt.title(\"Average face\")\n",
        "plt.show()\n",
        "\n",
        "# Plot first 5 eigenfaces\n",
        "fig2 = plt.figure(figsize=(10, 3))\n",
        "ax = fig2.add_subplot(161)\n",
        "img_avg = ax.imshow(np.reshape(avgFace,(m,n)).T)\n",
        "img_avg.set_cmap('gray')\n",
        "ax.set_title(\"Average Face\")\n",
        "plt.axis('off')\n",
        "\n",
        "for i in range(5):\n",
        "  ax = fig2.add_subplot(1, 6, i+2)\n",
        "  img = ax.imshow(np.reshape(U[:,i],(m,n)).T)\n",
        "  img.set_cmap('gray')\n",
        "  ax.set_title(f\"Eigenface {i+1}\")\n",
        "  plt.axis('off')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fbbd913e-9741-460b-89fb-d54c4d7f730f",
      "metadata": {
        "id": "fbbd913e-9741-460b-89fb-d54c4d7f730f"
      },
      "outputs": [],
      "source": [
        "fig3 = plt.figure(figsize=(10, 5), tight_layout=True)\n",
        "ax1 = fig3.add_subplot(121)\n",
        "ax1.semilogy(S,'-o',color='k')\n",
        "ax1.set(xlabel='r', ylabel='Singular values $\\sigma{}_r$')\n",
        "ax2 = fig3.add_subplot(122)\n",
        "ax2.plot(np.cumsum(S)/np.sum(S),'-o',color='k')\n",
        "ax2.set(xlabel='r', ylabel='Cumulative energy')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "415584ba-24b7-46bc-8e6a-95fb0b917c84",
      "metadata": {
        "id": "415584ba-24b7-46bc-8e6a-95fb0b917c84"
      },
      "outputs": [],
      "source": [
        "n_components = 150\n",
        "var = np.sum(S[:n_components])/np.sum(S)\n",
        "print(f\"Amount of variance captured by first {n_components} eigenfaces: {var*100:.1f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "64ac5fee-2d8c-4071-8013-51ef41c48e2e",
      "metadata": {
        "id": "64ac5fee-2d8c-4071-8013-51ef41c48e2e"
      },
      "outputs": [],
      "source": [
        "testFace = faces[:,np.sum(nfaces[:36])]\n",
        "\n",
        "testFaceMS = testFace - avgFace\n",
        "r_list = [25, 50, 100, 200, 400, 800, 1600]\n",
        "width = 4\n",
        "height = int(np.ceil(len(r_list)/width))\n",
        "fig4 = plt.figure(figsize=(12, 8))\n",
        "ax = fig4.add_subplot(height, width, 1)\n",
        "img = ax.imshow(np.reshape(testFace,(m,n)).T)\n",
        "img.set_cmap('gray')\n",
        "ax.set_title('Original Image')\n",
        "plt.axis('off')\n",
        "\n",
        "for r in r_list:\n",
        "    reconFace = avgFace + U[:,:r] @ (U[:,:r].T @ testFaceMS)\n",
        "    ax = fig4.add_subplot(height, width, r_list.index(r)+2)\n",
        "    img = ax.imshow(np.reshape(reconFace,(m,n)).T)\n",
        "    img.set_cmap('gray')\n",
        "    ax.set_title('r = ' + str(r))\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "be96f139-9b4b-408f-8f8e-0555725e7e8d",
      "metadata": {
        "id": "be96f139-9b4b-408f-8f8e-0555725e7e8d"
      },
      "outputs": [],
      "source": [
        "testFace = faces[:,np.sum(nfaces[:35])]\n",
        "\n",
        "testFaceMS = testFace - avgFace\n",
        "r_list = [25, 50, 100, 200, 400, 800, 1600]\n",
        "plt.imshow(np.reshape(testFace,(m,n)).T)\n",
        "plt.set_cmap('gray')\n",
        "plt.title('Original Image')\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "print(f\"Original size: {testFace.shape}\")\n",
        "\n",
        "for r in r_list:\n",
        "    comprFace = U[:,:r].T @ testFaceMS\n",
        "    print(f\"Compressed size: {comprFace.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7fe805ac-2ebd-4626-a04f-82ba9db752d6",
      "metadata": {
        "id": "7fe805ac-2ebd-4626-a04f-82ba9db752d6"
      },
      "outputs": [],
      "source": [
        "P1num = 2\n",
        "P2num = 7\n",
        "\n",
        "P1 = faces[:, np.sum(nfaces[:(P1num-1)]):np.sum(nfaces[:P1num])]\n",
        "P2 = faces[:, np.sum(nfaces[:(P2num-1)]):np.sum(nfaces[:P2num])]\n",
        "\n",
        "P1 = P1 - np.tile(avgFace, (P1.shape[1],1)).T\n",
        "P2 = P2 - np.tile(avgFace, (P2.shape[1],1)).T\n",
        "\n",
        "PCAmodes = [5, 6]\n",
        "\n",
        "PCACoordsP1 = U[:, PCAmodes-np.ones_like(PCAmodes)].T @ P1\n",
        "PCACoordsP2 = U[:, PCAmodes-np.ones_like(PCAmodes)].T @ P2\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "\n",
        "ax.plot(PCACoordsP1[0, :], PCACoordsP1[1, :], 'd', color='k', label=f\"Person {P1num}\")\n",
        "ax.plot(PCACoordsP2[0, :], PCACoordsP2[1, :], '^', color='r', label=f\"Person {P2num}\")\n",
        "\n",
        "ax.set(xlabel=\"PC 5\", ylabel=\"PC 6\")\n",
        "ax.grid()\n",
        "ax.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6c1b393c-fd71-454b-872e-0046174da2c8",
      "metadata": {
        "id": "6c1b393c-fd71-454b-872e-0046174da2c8"
      },
      "source": [
        "# PCA Feature Extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "821713b6-7ac7-4d22-ac24-a812ec4c79be",
      "metadata": {
        "id": "821713b6-7ac7-4d22-ac24-a812ec4c79be"
      },
      "outputs": [],
      "source": [
        "from utils import *\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "plt.rcParams['figure.figsize'] = [8, 8]\n",
        "plt.rcParams.update({'font.size': 18})\n",
        "\n",
        "X = faces.T\n",
        "y = np.zeros((faces.shape[1], 1))\n",
        "\n",
        "j = 0\n",
        "classes = list(range(len(nfaces)))\n",
        "for i in nfaces:\n",
        "  y[j:j+i] = classes.pop(0)\n",
        "  j = j + i"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "96619b28-6660-42b9-9595-c993ff008545",
      "metadata": {
        "id": "96619b28-6660-42b9-9595-c993ff008545"
      },
      "outputs": [],
      "source": [
        "X_tv, X_test, y_tv, y_test = train_test_split(X, y, test_size=0.4, shuffle=True, stratify=y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "885f08f4-8b83-4665-b740-dedc189f7aec",
      "metadata": {
        "id": "885f08f4-8b83-4665-b740-dedc189f7aec"
      },
      "outputs": [],
      "source": [
        "n_components = 150\n",
        "\n",
        "print(\"Extracting the top %d eigenfaces from %d faces\"\n",
        "      % (n_components, X_tv.shape[0]))\n",
        "t0 = time()\n",
        "pca = PCA(n_components=n_components, svd_solver='randomized',\n",
        "          whiten=True).fit(X_tv)\n",
        "print(\"done in %0.3fs\" % (time() - t0))\n",
        "\n",
        "eigenfaces = pca.components_.reshape((n_components, m, n))\n",
        "\n",
        "print(\"Projecting the input data on the eigenfaces orthonormal basis\")\n",
        "t0 = time()\n",
        "X_tv_pca = pca.transform(X_tv)\n",
        "X_test_pca = pca.transform(X_test)\n",
        "print(\"done in %0.3fs\" % (time() - t0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2065440b-1f7b-4f11-b2b6-9af06c157f8c",
      "metadata": {
        "id": "2065440b-1f7b-4f11-b2b6-9af06c157f8c"
      },
      "outputs": [],
      "source": [
        "person = 1\n",
        "subset = faces[:,sum(nfaces[:person]) : sum(nfaces[:(person+1)])]\n",
        "subset = subset[:, :8] # only take first 8 faces of person 1\n",
        "data = pca.transform(subset.T)\n",
        "fileName = \"PCAfeatures\"\n",
        "\n",
        "plot_features(data[:, :16])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f54d479d-5951-4a0b-97b2-8cddfe8277f3",
      "metadata": {
        "id": "f54d479d-5951-4a0b-97b2-8cddfe8277f3"
      },
      "outputs": [],
      "source": [
        "# Plot first 5 eigenfaces\n",
        "fig1 = plt.figure(figsize=(10, 3))\n",
        "\n",
        "for i in range(5):\n",
        "  ax = fig1.add_subplot(1, 5, i+1)\n",
        "  img = ax.imshow(eigenfaces[i].T)\n",
        "  img.set_cmap('gray')\n",
        "  ax.set_title(f\"Eigenface {i+1}\")\n",
        "  plt.axis('off')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7feaafe0-a0fd-48c9-a5ae-311232b7361c",
      "metadata": {
        "id": "7feaafe0-a0fd-48c9-a5ae-311232b7361c"
      },
      "outputs": [],
      "source": [
        "print(\"Fitting the classifier to the training set\")\n",
        "t0 = time()\n",
        "param_grid = {'C': [1e3, 5e3, 1e4, 5e4, 1e5],\n",
        "              'gamma': [0.0001, 0.0005, 0.001, 0.005, 0.01, 0.1], }\n",
        "clf = GridSearchCV(\n",
        "    SVC(kernel='rbf', class_weight='balanced'), param_grid\n",
        ")\n",
        "clf = clf.fit(X_tv_pca, y_tv.ravel())\n",
        "print(\"done in %0.3fs\" % (time() - t0))\n",
        "print(\"Best estimator found by grid search:\")\n",
        "print(clf.best_estimator_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "616babed-f7cc-4306-9cab-4c97ef4455b0",
      "metadata": {
        "id": "616babed-f7cc-4306-9cab-4c97ef4455b0"
      },
      "outputs": [],
      "source": [
        "print(\"Predicting people's names on the test set\")\n",
        "t0 = time()\n",
        "y_pred = clf.predict(X_test_pca)\n",
        "print(\"done in %0.3fs\" % (time() - t0))\n",
        "\n",
        "target_names = [f\"Person{n}\" for n in range(1,39)]\n",
        "\n",
        "print(classification_report(y_test, y_pred, target_names=target_names))\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "acc_pca = accuracy_score(y_test, y_pred)\n",
        "print(f\"PCA Baseline Accuracy: {acc_pca:.2%}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6086dee7-595f-4217-9506-56bea4fde760",
      "metadata": {
        "id": "6086dee7-595f-4217-9506-56bea4fde760"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "\n",
        "plt.rcParams.update({'font.size': 10})\n",
        "plt.rcParams['figure.figsize'] = [12, 12]\n",
        "\n",
        "disp = ConfusionMatrixDisplay.from_estimator(\n",
        "    clf,\n",
        "    X_test_pca,\n",
        "    y_test,\n",
        "    cmap=plt.cm.Blues,\n",
        "    display_labels=range(1, 39)\n",
        ")\n",
        "\n",
        "plt.grid(False)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "10c62f65-97d6-4baf-a854-2e718605e35e",
      "metadata": {
        "id": "10c62f65-97d6-4baf-a854-2e718605e35e"
      },
      "outputs": [],
      "source": [
        "# plot the result of the prediction on a portion of the test set\n",
        "\n",
        "prediction_titles = [title(y_pred, y_test, target_names, i) for i in range(y_pred.shape[0])]\n",
        "plot_gallery(X_test, prediction_titles, m, n)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "77d0f79e-652a-4c3f-823d-21caed56a690",
      "metadata": {
        "id": "77d0f79e-652a-4c3f-823d-21caed56a690"
      },
      "source": [
        "# Autoencoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8b22f385-003a-46ff-94df-c4b2cd73c73c",
      "metadata": {
        "id": "8b22f385-003a-46ff-94df-c4b2cd73c73c"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import Model, Sequential\n",
        "from tensorflow.keras.layers import Input, Convolution2D, LocallyConnected2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "plt.rcParams.update({'font.size': 11})\n",
        "plt.rcParams['figure.constrained_layout.use'] = True\n",
        "\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  print('Found GPU at: {}'.format(device_name))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1fa95d2b-65e0-46cd-8caf-8fa48983ba9b",
      "metadata": {
        "id": "1fa95d2b-65e0-46cd-8caf-8fa48983ba9b"
      },
      "outputs": [],
      "source": [
        "allFaces = faces.T\n",
        "y = np.zeros((faces.shape[1], 1))\n",
        "M = allFaces.reshape(allFaces.shape[0], m, n)\n",
        "dataset = preprocess_faces(M)\n",
        "\n",
        "j = 0\n",
        "classes = list(range(len(nfaces)))\n",
        "for i in nfaces:\n",
        "  y[j:j+i] = classes.pop(0)\n",
        "  j = j + i"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "44689ef3-f277-4a6e-9674-abea98a48e79",
      "metadata": {
        "id": "44689ef3-f277-4a6e-9674-abea98a48e79"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "model.add(Convolution2D(32, (11, 11), activation='relu', name='C1', input_shape=(152, 152, 3)))\n",
        "model.add(MaxPooling2D(pool_size=3, strides=2, padding='same', name='M2'))\n",
        "model.add(Convolution2D(16, (9, 9), activation='relu', name='C3'))\n",
        "model.add(LocallyConnected2D(16, (9, 9), activation='relu', name='L4'))\n",
        "model.add(LocallyConnected2D(16, (7, 7), strides=2, activation='relu', name='L5') )\n",
        "model.add(LocallyConnected2D(16, (5, 5), activation='relu', name='L6'))\n",
        "model.add(Flatten(name='F0'))\n",
        "model.add(Dense(4096, activation='relu', name='F7'))\n",
        "model.add(Dropout(rate=0.5, name='D0'))\n",
        "model.add(Dense(8631, activation='softmax', name='F8'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "encoder = Model(inputs=model.layers[0].input, outputs=model.layers[-3].output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "52f67ee0-6cbc-42fd-bbdf-e7232c8f04cc",
      "metadata": {
        "id": "52f67ee0-6cbc-42fd-bbdf-e7232c8f04cc"
      },
      "outputs": [],
      "source": [
        "weights = get_weights()\n",
        "model.load_weights(weights)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "adf44899-640a-4af8-a3cc-49e3b89586de",
      "metadata": {
        "id": "adf44899-640a-4af8-a3cc-49e3b89586de"
      },
      "outputs": [],
      "source": [
        "print(\"Feature generation of face library\")\n",
        "t0 = time()\n",
        "person = 0\n",
        "subset = dataset[sum(nfaces[:person]): sum(nfaces[:(person+1)])]\n",
        "subset = encoder.predict(subset/255)\n",
        "print(\"done in %0.3fs\" % (time() - t0))\n",
        "plot_features(subset[:8, :16])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c7a9168-8cd0-4055-ae4d-ba23da1e12e5",
      "metadata": {
        "id": "4c7a9168-8cd0-4055-ae4d-ba23da1e12e5"
      },
      "outputs": [],
      "source": [
        "def l2_normalize(x):\n",
        "    return x / np.sqrt(np.sum(np.multiply(x, x)))\n",
        "\n",
        "def findEuclideanDistance(source_representation, test_representation):\n",
        "    euclidean_distance = source_representation - test_representation\n",
        "    euclidean_distance = np.sum(np.multiply(euclidean_distance, euclidean_distance))\n",
        "    euclidean_distance = np.sqrt(euclidean_distance)\n",
        "    return euclidean_distance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "36d1ed1b-d578-4b09-bf07-7fae23b840e5",
      "metadata": {
        "id": "36d1ed1b-d578-4b09-bf07-7fae23b840e5"
      },
      "outputs": [],
      "source": [
        "img1_path = 1\n",
        "img2_path = 2\n",
        "target = True\n",
        "\n",
        "print(img1_path, \" and \", img2_path)\n",
        "\n",
        "img1 = dataset[img1_path]/255\n",
        "img2 = dataset[img2_path]/255\n",
        "\n",
        "fig = plt.figure()\n",
        "fig.add_subplot(1,2, 1)\n",
        "plt.imshow(img1)\n",
        "plt.xticks([]); plt.yticks([])\n",
        "fig.add_subplot(1,2, 2)\n",
        "plt.imshow(img2)\n",
        "plt.xticks([]); plt.yticks([])\n",
        "plt.show(block=True)\n",
        "\n",
        "img1_embedding = encoder.predict(np.expand_dims(img1, axis=0))\n",
        "img2_embedding = encoder.predict(np.expand_dims(img2, axis=0))\n",
        "\n",
        "\n",
        "euclidean_distance = findEuclideanDistance(img1_embedding, img2_embedding)\n",
        "euclidean_l2_distance = findEuclideanDistance(l2_normalize(img1_embedding), l2_normalize(img2_embedding))\n",
        "\n",
        "print(\"Euclidean L2 distance: \", euclidean_l2_distance)\n",
        "print(\"Actual: \", target, end = '')\n",
        "\n",
        "if euclidean_l2_distance <= 0.55:\n",
        "    verified = True\n",
        "else:\n",
        "    verified = False\n",
        "\n",
        "print(\" - Predicted: \", verified)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "58e3ea79-8c02-4ba2-a820-863290e57fe6",
      "metadata": {
        "id": "58e3ea79-8c02-4ba2-a820-863290e57fe6"
      },
      "outputs": [],
      "source": [
        "input_layer = Input(shape=4096)\n",
        "output = Dense(units=len(nfaces), activation='softmax')(input_layer)\n",
        "clf = Model(input_layer, output)\n",
        "clf.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
        "clf.summary()\n",
        "accuracy = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "350aac60-5d2e-47eb-b1e2-a52577364a64",
      "metadata": {
        "id": "350aac60-5d2e-47eb-b1e2-a52577364a64"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "def build_fresh_classifier():\n",
        "    input_layer = Input(shape=4096)\n",
        "    output = Dense(units=len(nfaces), activation='softmax')(input_layer)\n",
        "    model = Model(input_layer, output)\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# EXPERIMENT 1: The \"Control\" (Standard Split)\n",
        "print(\"\\n--- RUNNING EXPERIMENT 1: STANDARD SPLIT (Control) ---\")\n",
        "X_train_std, X_test_std, y_train_std, y_test_std = train_test_split(dataset, y, test_size=0.4, shuffle=True, stratify=y)\n",
        "\n",
        "y_train_std_enc = tf.keras.utils.to_categorical(y_train_std, num_classes=len(nfaces))\n",
        "X_train_std_enc = encoder.predict(X_train_std/255)\n",
        "X_test_std_enc = encoder.predict(X_test_std/255)\n",
        "\n",
        "# Train Model A\n",
        "clf_std = build_fresh_classifier()\n",
        "hist_std = clf_std.fit(X_train_std_enc, y_train_std_enc, batch_size=64, epochs=40, verbose=0, validation_split=0.1)\n",
        "\n",
        "y_pred_std = np.argmax(clf_std.predict(X_test_std_enc), axis=1)\n",
        "acc_std = accuracy_score(y_test_std, y_pred_std)\n",
        "print(f\"RESULT: Standard Split Accuracy = {acc_std*100:.2f}%\")\n",
        "\n",
        "\n",
        "# EXPERIMENT 2: The \"Gap\" (Single Sample Split)\n",
        "print(\"\\n--- RUNNING EXPERIMENT 2: SINGLE SAMPLE (Experimental) ---\")\n",
        "X_train_sspp = []\n",
        "y_train_sspp = []\n",
        "X_test_sspp = []\n",
        "y_test_sspp = []\n",
        "\n",
        "current_index = 0\n",
        "for count in nfaces:\n",
        "    # 1. Take ONLY the FIRST image for Training\n",
        "    X_train_sspp.append(dataset[current_index])\n",
        "    y_train_sspp.append(y[current_index])\n",
        "\n",
        "    # 2. All others go to Testing\n",
        "    if count > 1:\n",
        "        X_test_sspp.append(dataset[current_index + 1 : current_index + count])\n",
        "        y_test_sspp.append(y[current_index + 1 : current_index + count])\n",
        "    current_index += count\n",
        "\n",
        "X_train_sspp = np.array(X_train_sspp)\n",
        "y_train_sspp = np.array(y_train_sspp)\n",
        "X_test_sspp = np.vstack(X_test_sspp)\n",
        "y_test_sspp = np.vstack(y_test_sspp)\n",
        "\n",
        "y_train_sspp_enc = tf.keras.utils.to_categorical(y_train_sspp, num_classes=len(nfaces))\n",
        "X_train_sspp_enc = encoder.predict(X_train_sspp/255)\n",
        "X_test_sspp_enc = encoder.predict(X_test_sspp/255)\n",
        "\n",
        "# Train Model B\n",
        "clf_sspp = build_fresh_classifier()\n",
        "hist_sspp = clf_sspp.fit(X_train_sspp_enc, y_train_sspp_enc, batch_size=64, epochs=40, verbose=0, validation_split=0.1)\n",
        "\n",
        "y_pred_sspp = np.argmax(clf_sspp.predict(X_test_sspp_enc), axis=1)\n",
        "acc_sspp = accuracy_score(y_test_sspp, y_pred_sspp)\n",
        "print(f\"RESULT: Single Sample Accuracy = {acc_sspp*100:.2f}%\")\n",
        "\n",
        "\n",
        "# Visualization\n",
        "labels = ['Standard (Many Images)', 'Single Sample (1 Image)']\n",
        "accuracies = [acc_std * 100, acc_sspp * 100]\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "bars = plt.bar(labels, accuracies, color=['green', 'red'])\n",
        "plt.ylabel('Accuracy (%)')\n",
        "plt.title('Impact of Data Scarcity on Convolutional Autoencoder')\n",
        "plt.ylim(0, 100)\n",
        "\n",
        "for bar in bars:\n",
        "    yval = bar.get_height()\n",
        "    plt.text(bar.get_x() + bar.get_width()/2, yval + 1, f\"{yval:.1f}%\", ha='center', fontweight='bold')\n",
        "\n",
        "plt.show()\n",
        "\n",
        "clf = clf_sspp\n",
        "X_test = X_test_sspp\n",
        "y_test = y_test_sspp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "60211a8a-c555-499f-8d32-1e9d0f7da6af",
      "metadata": {
        "id": "60211a8a-c555-499f-8d32-1e9d0f7da6af"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create subplots\n",
        "fig, ax = plt.subplots(2, 1, figsize=(10, 8))\n",
        "\n",
        "# Plot Loss for Standard Split\n",
        "ax[0].plot(hist_std.history['loss'], color='b', label=\"Training loss\")\n",
        "ax[0].plot(hist_std.history['val_loss'], color='r', label=\"Validation loss\")\n",
        "ax[0].set_ylabel(\"Crossentropy Loss\")\n",
        "ax[0].legend(loc='best', shadow=True)\n",
        "ax[0].set_title(\"Experiment 1: Standard Split Training Performance\")\n",
        "\n",
        "# Plot Accuracy for Standard Split\n",
        "ax[1].plot(hist_std.history['accuracy'], color='b', label=\"Training accuracy\")\n",
        "ax[1].plot(hist_std.history['val_accuracy'], color='r', label=\"Validation accuracy\")\n",
        "ax[1].set_xlabel(\"Epoch\")\n",
        "ax[1].set_ylabel(\"Accuracy\")\n",
        "ax[1].legend(loc='best', shadow=True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "869159cc-e301-4d18-8ae9-6c3c4eca92d2",
      "metadata": {
        "id": "869159cc-e301-4d18-8ae9-6c3c4eca92d2"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "# 1. Compute the confusion matrix for the Standard Split\n",
        "conf_matrix_std = confusion_matrix(y_test_std, y_pred_std)\n",
        "\n",
        "# 2. Setup plot sizing\n",
        "plt.rcParams.update({'font.size': 8})\n",
        "plt.rcParams['figure.figsize'] = [12, 12]\n",
        "\n",
        "# 3. Display the matrix\n",
        "disp = ConfusionMatrixDisplay(\n",
        "    confusion_matrix=conf_matrix_std,\n",
        "    display_labels=range(1, len(nfaces) + 1)\n",
        ")\n",
        "\n",
        "disp.plot(cmap=plt.cm.Greens, colorbar=False)\n",
        "plt.title(\"Confusion Matrix: Standard Split (Regular Training)\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2151099f-d31a-49ff-9d70-82779a05e434",
      "metadata": {
        "id": "2151099f-d31a-49ff-9d70-82779a05e434"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(2,1, figsize=(10, 8))\n",
        "\n",
        "# Plot Loss\n",
        "ax[0].plot(hist_sspp.history['loss'], color='b', label=\"Training loss\")\n",
        "ax[0].plot(hist_sspp.history['val_loss'], color='r', label=\"Validation loss\")\n",
        "ax[0].set_ylabel(\"Crossentropy Loss\")\n",
        "ax[0].legend(loc='best', shadow=True)\n",
        "ax[0].set_title(\"Single Sample Training Performance\")\n",
        "\n",
        "# Plot Accuracy\n",
        "ax[1].plot(hist_sspp.history['accuracy'], color='b', label=\"Training accuracy\")\n",
        "ax[1].plot(hist_sspp.history['val_accuracy'], color='r',label=\"Validation accuracy\")\n",
        "ax[1].set_xlabel(\"Epoch\")\n",
        "ax[1].set_ylabel(\"Accuracy\")\n",
        "ax[1].legend(loc='best', shadow=True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5587102f-0499-41f4-8b29-2cb48cf39f99",
      "metadata": {
        "id": "5587102f-0499-41f4-8b29-2cb48cf39f99"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "print(\"Predicting people's names on the Single Sample test set...\")\n",
        "t0 = time()\n",
        "\n",
        "X_test_enc = encoder.predict(X_test/255)\n",
        "\n",
        "# Predict\n",
        "y_pred = clf.predict(X_test_enc)\n",
        "y_pred = np.argmax(y_pred, axis=1)\n",
        "\n",
        "print(\"done in %0.3fs\" % (time() - t0))\n",
        "\n",
        "target_names = [f\"Person{n}\" for n in range(1,39)]\n",
        "\n",
        "print(classification_report(y_test.ravel(), y_pred, target_names=target_names))\n",
        "\n",
        "confusion_mtx = confusion_matrix(y_test.ravel(), y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4ee320da-9d9a-4316-bbf0-476e320a449c",
      "metadata": {
        "id": "4ee320da-9d9a-4316-bbf0-476e320a449c"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "\n",
        "plt.rcParams.update({'font.size': 8})\n",
        "plt.rcParams['figure.figsize'] = [12, 12]\n",
        "\n",
        "# Display the matrix for the Single Sample experiment\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=confusion_mtx, display_labels=range(1, 39))\n",
        "\n",
        "disp.plot(cmap=plt.cm.Reds, colorbar=False)\n",
        "plt.title(\"Confusion Matrix: Single Sample Per Person\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "02421998-7c50-474c-91f0-1c09a77fb656",
      "metadata": {
        "id": "02421998-7c50-474c-91f0-1c09a77fb656"
      },
      "outputs": [],
      "source": [
        "# plot the result of the prediction on a portion of the test set\n",
        "prediction_titles = [title(y_pred, y_test, target_names, i) for i in range(y_pred.shape[0])]\n",
        "plot_gallery(X_test, prediction_titles, m, n, rgb=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5cc6e6e5-12a5-418e-a378-6916c8cbc33c",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true,
        "id": "5cc6e6e5-12a5-418e-a378-6916c8cbc33c"
      },
      "source": [
        "# Reconstruction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b70bef35-e82f-4e17-8235-3500c645595b",
      "metadata": {
        "id": "b70bef35-e82f-4e17-8235-3500c645595b"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from PIL import Image\n",
        "\n",
        "TARGET_SIZE = (64, 64)\n",
        "\n",
        "imgs = np.array(dataset)\n",
        "\n",
        "processed = []\n",
        "\n",
        "for i, im in enumerate(imgs):\n",
        "    im_uint8 = im.astype(\"uint8\")\n",
        "    im_pil = Image.fromarray(im_uint8)\n",
        "    im_gray = im_pil.convert(\"L\").resize(TARGET_SIZE, Image.BILINEAR)\n",
        "    arr = np.array(im_gray).astype(\"float32\") / 255.0\n",
        "    processed.append(arr)\n",
        "\n",
        "processed = np.stack(processed)\n",
        "processed = processed[..., np.newaxis]\n",
        "\n",
        "print(\"Processed image shape:\", processed.shape)\n",
        "\n",
        "# Train/test split for reconstruction\n",
        "x_train, x_test = train_test_split(processed, test_size=0.2, random_state=42, shuffle=True)\n",
        "\n",
        "print(\"x_train:\", x_train.shape)\n",
        "print(\"x_test:\", x_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7c1cf91d-494c-40fb-8d38-4e4478977bf1",
      "metadata": {
        "id": "7c1cf91d-494c-40fb-8d38-4e4478977bf1"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import layers, models\n",
        "\n",
        "latent_dim = 128\n",
        "\n",
        "# Encoder\n",
        "encoder_input = layers.Input(shape=(64, 64, 1))\n",
        "x = layers.Conv2D(32, (3,3), activation='relu', padding='same')(encoder_input)\n",
        "x = layers.MaxPooling2D((2,2), padding='same')(x)   # 32×32\n",
        "x = layers.Conv2D(64, (3,3), activation='relu', padding='same')(x)\n",
        "x = layers.MaxPooling2D((2,2), padding='same')(x)   # 16×16\n",
        "x = layers.Flatten()(x)\n",
        "encoder_output = layers.Dense(latent_dim, activation='relu')(x)\n",
        "\n",
        "encoder = models.Model(encoder_input, encoder_output, name=\"encoder\")\n",
        "encoder.summary()\n",
        "\n",
        "# Decoder\n",
        "decoder_input = layers.Input(shape=(latent_dim,))\n",
        "x = layers.Dense(16*16*64, activation='relu')(decoder_input)\n",
        "x = layers.Reshape((16, 16, 64))(x)\n",
        "x = layers.Conv2DTranspose(64, (3,3), strides=2, activation='relu', padding='same')(x)  # 32×32\n",
        "x = layers.Conv2DTranspose(32, (3,3), strides=2, activation='relu', padding='same')(x)  # 64×64\n",
        "decoder_output = layers.Conv2D(1, (3,3), activation='sigmoid', padding='same')(x)\n",
        "\n",
        "decoder = models.Model(decoder_input, decoder_output, name=\"decoder\")\n",
        "decoder.summary()\n",
        "\n",
        "# Autoencoder\n",
        "autoencoder_output = decoder(encoder_output)\n",
        "autoencoder = models.Model(encoder_input, autoencoder_output, name=\"autoencoder\")\n",
        "autoencoder.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "autoencoder.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "48a67c45-dae4-4ef1-957a-7fdbf197b2b6",
      "metadata": {
        "id": "48a67c45-dae4-4ef1-957a-7fdbf197b2b6"
      },
      "outputs": [],
      "source": [
        "history = autoencoder.fit(\n",
        "    x_train, x_train,\n",
        "    epochs=50,\n",
        "    batch_size=64,\n",
        "    shuffle=True,\n",
        "    validation_split=0.2\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f41a7e26-bd20-49aa-87e6-4370d50d1dfc",
      "metadata": {
        "id": "f41a7e26-bd20-49aa-87e6-4370d50d1dfc"
      },
      "outputs": [],
      "source": [
        "decoded_imgs = autoencoder.predict(x_test)\n",
        "\n",
        "n = 10\n",
        "plt.figure(figsize=(20, 4))\n",
        "\n",
        "for i in range(n):\n",
        "    # Original\n",
        "    ax = plt.subplot(2, n, i + 1)\n",
        "    plt.imshow(x_test[i].reshape(64,64), cmap='gray')\n",
        "    plt.title(\"Original\")\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "    # Reconstructed\n",
        "    ax = plt.subplot(2, n, i + 1 + n)\n",
        "    plt.imshow(decoded_imgs[i].reshape(64,64), cmap='gray')\n",
        "    plt.title(\"Reconstructed\")\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "24178cc0-8eee-4707-9e1c-cb4e65c1b3c4",
      "metadata": {
        "id": "24178cc0-8eee-4707-9e1c-cb4e65c1b3c4"
      },
      "outputs": [],
      "source": [
        "from skimage.metrics import structural_similarity as ssim\n",
        "\n",
        "# Autoencoder prediction\n",
        "decoded_imgs = autoencoder.predict(x_test)\n",
        "\n",
        "mse_list = []\n",
        "ssim_list = []\n",
        "\n",
        "for i in range(len(x_test)):\n",
        "    orig = x_test[i].reshape(64,64)\n",
        "    recon = decoded_imgs[i].reshape(64,64)\n",
        "\n",
        "    mse_value = np.mean((orig - recon)**2)\n",
        "    ssim_value = ssim(orig, recon, data_range=1.0)\n",
        "\n",
        "    mse_list.append(mse_value)\n",
        "    ssim_list.append(ssim_value)\n",
        "\n",
        "mean_mse = np.mean(mse_list)\n",
        "mean_ssim = np.mean(ssim_list)\n",
        "\n",
        "print(\"Reconstruction Accuracy\")\n",
        "print(f\"Average MSE   : {mean_mse:.6f}\")\n",
        "print(f\"Average SSIM  : {mean_ssim:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5eaea058-053f-4839-abe4-aa85cf68be9b",
      "metadata": {
        "id": "5eaea058-053f-4839-abe4-aa85cf68be9b"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# Plot the Mean Squared Error (MSE)\n",
        "plt.plot(history.history['loss'], label='Training MSE', color='blue')\n",
        "plt.plot(history.history['val_loss'], label='Validation MSE', color='red')\n",
        "\n",
        "plt.title('Reconstruction Training Performance')\n",
        "plt.ylabel('Mean Squared Error')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(loc='upper right')\n",
        "plt.grid(True)\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "02ba9922-0084-455e-89be-8edb61cdaa62",
      "metadata": {
        "id": "02ba9922-0084-455e-89be-8edb61cdaa62"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}